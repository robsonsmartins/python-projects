{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Desafio PLN e Chatbots - SERPRO\n\n**Página do Desafio:** [https://www.kaggle.com/c/desafio-ia-2020-pln-chatbots/overview](https://www.kaggle.com/c/desafio-ia-2020-pln-chatbots/overview)\n\n---\n### Skynet\n\nRobson de Sousa Martins<br>\n[https://www.robsonmartins.com](https://www.robsonmartins.com)\n\n___\n\nEste desafio foi solucionado com a implementação da classificação das frases (perguntas de chatbot) em três etapas:\n\n1. **Pré-classificação das frases por palavras-chave**: Nesta etapa, as frases são classificadas através de comparação de suas palavras com um banco de palavras-chave prestabelecido. Assim, já são identificadas frases de assuntos não-relacionados aos grupos de bots sugeridos (e classificadas como `0: Nenhum`), e frases de assuntos amplamente conhecidos, como por exemplo as que contém a palavra `COVID-19` (classe `2: Covid`).\n\n2. **Classificação das frases restantes através de algoritmo**: Nessa fase, um algoritmo de classificação é selecionado, e realiza a classificação das frases restantes, baseado no aprendizado realizado com a massa de dados de treino.\n\n3. **Remoção de classificação de baixa probabilidade**: Frases classificadas com probabilidade mais baixa que um número mínimo definido, são desclassificadas, ou seja, clasificadas para `0: Nenhum`. Isso elimina alguns dos equívocos produzidos pelo algoritmo classificador e aumenta a qualidade do resultado.\n\n\nÉ importante que o conjunto de palavras-chave seja bem escolhido para que reflita fortemente cada uma das classes/assuntos propostos.\n\nPara este desafio, o classificador por palavras-chave foi implementado de maneira simples, sem realizar cálculo probabilístico da frequência ou peso de palavras-chave (ou seja, se ele simplesmente encontrar a palavra-chave na primeira classe avaliada, atribui uma probabilidade de 1.0 ou 100%, sem avaliar as outras classes subsequentes).\n\nNuma aplicação real, o conjunto de palavras-chave poderia ser dinâmico, atualizado periodicamente, alimentado por um banco de dados de palavras mais citadas por cada assunto, tal como numa nuvem de palavras, ou *trend topics* oriundos de um *data mining* de redes sociais, por exemplo."},{"metadata":{},"cell_type":"markdown","source":"# Bibliotecas utilizadas"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport csv\nimport re\nimport string\n\nimport nltk\n\nfrom nltk.corpus import stopwords as sw\nfrom nltk.tokenize import RegexpTokenizer\n\nfrom unicodedata import normalize\nfrom datetime import datetime, timedelta\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom statistics import mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vetorizador\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Clssificadores\nfrom sklearn.cluster import KMeans\nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import ComplementNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom catboost import CatBoostClassifier\nfrom xgboost.sklearn import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Download de Módulos"},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('stopwords')\nnltk.download('punkt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Desliga warnings desnecessários\npd.set_option('mode.chained_assignment',None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classes"},{"metadata":{},"cell_type":"markdown","source":"### DummyVectorizer\n\nVetorizador \"dummy\": não realiza nenhuma transformação de dados. Mantém apenas a interface de um vetorizador básico, padrão do sklearn."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.base import BaseEstimator\n\n# Vetorizador \"dummy\": não realiza nenhuma transformação de dados\n# Mantém apenas a interface de um Vetorizador básico\n\nclass DummyVectorizer(BaseEstimator):\n    \n    def __init__(self):\n        pass\n    \n    def fit(self, raw_documents, y=None):\n        return self\n    \n    def transform(self, raw_documents):\n        return np.array(raw_documents).reshape(-1, 1)\n    \n    def fit_transform(self,raw_documents, y=None):\n        self.fit(raw_documents, y)\n        return self.transform(raw_documents)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KeywordClassifier\n\nUm Classificador por palavras-chave (keywords). Este classificador foi construido com a mesma interface de um classificador do sklearn.\n\nO método fit() recebe um array de palavras-chave e classes a que se referem, em ordem de prioridade.\nO método predict() classifica frases de acordo com as palavras-chave treinadas com fit().\nUsa um stemmer de língua portuguesa para corresponder palavras similares (com mesma raiz)."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.utils.validation import check_X_y, check_array, check_is_fitted\nfrom sklearn.utils.multiclass import unique_labels\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem import RSLPStemmer\nfrom unicodedata import normalize\n\n# Classificador por palavras-chave (keywords).\n# Este classificador foi construido com a mesma interface de um classificador do sklearn.\n# O método fit() recebe um array de palavras-chave e classes a que se referem, em ordem de prioridade.\n# Se uma classe não contém palavras-chave (array vazio), será usada como padrão para registros que não forem classificados.\n# O método predict() classifica frases de acordo com as palavras-chave treinadas com fit().\n# Usa um stemmer de língua portuguesa para corresponder palavras similares (com mesma raiz).\n# Parâmetros:\n# verbose (default = True): indica se deve exibir informações detalhadas do progresso da classificação.\n\nclass KeywordClassifier(BaseEstimator, ClassifierMixin):\n    \n    verbose = True # verboso por padrao\n    classes_, X_, y_ = [], [], [] # classes, X e y\n\n    _cache = [] # classes e palavras-chave aprendidas com fit()\n    _y_default = None # classe default, caso não saiba classificar\n    \n    _tokenizer = RegexpTokenizer(r'\\w+') # tokenizador\n    _stemmer = RSLPStemmer() # stemmer de lingua portuguesa\n    \n    # construtor\n    def __init__(self,verbose=True):\n        self.verbose = verbose\n        if self.verbose:\n            print('KeywordClassifier: verbose mode started.')\n    \n    # fit(X,y): preenche _cache com as classes/keywords\n    def fit(self, X, y, sample_weight=None):\n        # check that X and y have correct shape\n        X, y = check_X_y(X, y, dtype=['object','int64','float64'])\n        # store the classes seen during fit\n        self.classes_ = unique_labels(y) # classes ordenadas\n        self.X_ = X # palavras-chave\n        self.y_ = y # classes\n        self._cache = []\n        for i in range(len(y)):\n            y_data = y[i]\n            X_data = X[i][0]\n            if len(X_data) == 0: self._y_default = y_data # pega classe default\n            self._cache.append({'y':y_data,'X':X_data}) # memoriza keywords/classes em _cache\n            if self.verbose:\n                print(f'fitting keywords {i+1}/{len(y)} ...')\n        return self\n\n    # predict(X): retorna classes (y) baseado na matriz de probabilidades\n    # retornada por predict_proba(X)\n    def predict(self, X):\n        # calcula matriz de probabilidades \n        _proba = self.predict_proba(X)\n        _predict = []\n        # varre cada sample da matriz e retorna classe correspondente para cada sample\n        for sample in _proba:\n            _cidx = -1\n            _cmax = 0.0\n            for i in range(len(sample)):\n                if sample[i] > _cmax:\n                    _cmax = sample[i]\n                    _cidx = i\n            _predict.append(self.classes_[_cidx]) # retorna classe (a de maior probabilidade na matriz)\n        return _predict\n    \n    # predict_proba(X): retorna matriz de probabilidades de cada sample, para\n    # cada classe inferida\n    # 0.0 = não há correspondência nos keywords (0% de probabilidade de ser da classe)\n    # 1.0 = há correspondência nos keywords (100% de probabilidade de ser da classe)\n    def predict_proba(self, X):\n        # check is fit had been called\n        check_is_fitted(self)\n        # input validation\n        X = check_array(X,dtype=['object','int64','float64'])\n        _proba = []\n        _count = []\n        _total = 0\n        # inicializa contador de samples/classe\n        for j in range(len(self.classes_)):\n            _count.append(0)\n        # varre cada sample de entrada\n        for i in range(len(X)):\n            phrase = X[i][0]  # uma frase de entrada\n            # inicializa matriz de probabilidades do sample\n            _proba_sample = []\n            for j in range(len(self.classes_)):\n                _proba_sample.append(0.0)\n            # procura correspondência de keywords\n            y = self._search_keywords(phrase)\n            if y == None: y = self._y_default  # se não encontrou, retorna classe default\n            # varre classes ordenadas\n            for j in range(len(self.classes_)):\n                if y == self.classes_[j]: # se a classe coincide\n                    _proba_sample[j] = 1.0  # registra na matriz a probabilidade 1.0 (100%)\n                    _count[j] = _count[j] + 1  # incrementa contagem de samples\n                    if y != self._y_default: _total = _total + 1  # incrementa total de samples classificados\n                    break\n            _proba.append(_proba_sample)\n            if self.verbose and ((i+1) == 1 or (i+1) % 100 == 0 or (i+1) == len(X)):\n                print(f'predict sample {i+1}/{len(X)} ...')\n        # exibe relatório, se verboso\n        if self.verbose and _total != 0:\n            print(f'{_total}/{len(X)} ({round(_total*100/len(X),1)}%) samples predicted.')\n            print('-----------------')\n            print(' class | samples ')\n            print('-----------------')\n            for j in range(len(self.classes_)): \n                print(f'{self.classes_[j]:^7}|{_count[j]:^9}')\n            print('-----------------')\n        return _proba\n    \n    # predict_log_proba(X): mesmo que predict_proba(X), porém resultados em log (base e)\n    def predict_log_proba(self, X):\n        return np.log(self.predict_proba(X))\n    \n    # partial_fit(X,y): implementado como o mesmo que fit(X,y)\n    def partial_fit(self, X, y, classes=None, sample_weight=None):\n        return self.fit(X, y, sample_weight)\n\n    # busca palavras no _cache de keywords, e retorna a classe (y), se encontrada correspondência,\n    # ou None se não.\n    def _search_keywords(self, text):\n        tokens = self._tokenizer.tokenize(text.lower())\n        found = []\n        kwparts = []\n        for i in range(len(self._cache)): # keywords classificados por prioridade\n            data = self._cache[i]\n            X = data['X']\n            y = data['y']\n            if len(X) == 0: X = [''] # sem keywords\n            for kword_phrase in X:\n                kword_phrase = kword_phrase.strip()\n                kwparts = []\n                found = []\n                if kword_phrase == '': # classe default (sem keywords)\n                    found.append(y)\n                    kwparts.append('')\n                    break\n                if kword_phrase.find(' ') != -1: # operação and\n                    kwparts = kword_phrase.split()\n                else:\n                    kwparts.append(kword_phrase)\n                for kwitem in kwparts:\n                    as_is = kwitem[0].isupper()\n                    if as_is: # keyword como é (sem stemmer)\n                        skw = kwitem.lower()\n                    else:\n                        skw = self._stem(kwitem) # keyword flexionada (stemmer para achar raiz da palavra)\n                    # remove acentos\n                    skw = self._ascii(skw)\n                    for word in tokens:\n                        if word == '': continue\n                        # remove acentos\n                        word = self._ascii(word)\n                        if (as_is and word == skw) or (not as_is and word.startswith(skw)):\n                            found.append(y)\n                            break\n                if len(kwparts) != 0 and len(found) == len(kwparts):\n                    break\n            if len(kwparts) != 0 and len(found) == len(kwparts):\n                break\n        if len(found) != 0 and len(found) == len(kwparts):\n            return found[0]\n        else:\n            return None\n    \n    # retorna a raiz (flexão) das palavras\n    def _stem(self, text):\n        _phrase = []\n        _tokens = self._tokenizer.tokenize(text)\n        for word in _tokens:\n            _phrase.append(self._stemmer.stem(word))\n        return \" \".join(_phrase)\n    \n    # remove acentos\n    def _ascii(self, text):\n        return normalize('NFKD', text).encode('ASCII', 'ignore').decode('ASCII')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Funções"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Realiza uma limpeza bem básica de um texto, preparando-o para classificação. \ndef limpar_texto(texto):\n    # Converte para minúsculas\n    texto = texto.lower()\n    # Remove números\n    texto = re.sub(r'[0-9]+',' ',texto)\n    # Remove pontuacao\n    texto = texto.translate(str.maketrans(string.punctuation,' '*len(string.punctuation)))\n    # Remove espacos extras\n    texto = re.sub(r'\\s+',' ',texto)\n    # Remove stopwords\n    tokens = tokenizer.tokenize(texto)\n    tokens = [palavra.strip() for palavra in tokens if palavra not in stopwords]\n    texto = ' '.join(tokens)  \n    # Remove acentos\n    texto = normalize('NFKD',texto).encode('ASCII','ignore').decode('ASCII')\n    # cria dict de palavras unicas\n    # remove palavras menores que 2 caracteres\n    tokens = tokenizer.tokenize(texto)\n    fdist = nltk.FreqDist(tokens)\n    tokens = [palavra.strip() for palavra, freq in fdist.items() if len(palavra) >= 2]\n    texto = ' '.join(tokens)  \n    return texto","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calcula métricas de desempenho do classificador. Fique à vontade para incluir outras métricas que julgar úteis.\n# Lembre-se, todavia, que o desafio utiliza a métrica F1 (macro) para avaliação dos resultados. \n# Referência: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n\ndef get_metrics(y_test, y_predicted, average='macro'):  \n    precision = round(precision_score(y_test, y_predicted, pos_label=1, average=average, zero_division=0),4)             \n    recall = round(recall_score(y_test, y_predicted, pos_label=1, average=average, zero_division=0),4)\n    f1 = round(f1_score(y_test, y_predicted, pos_label=1, average=average, zero_division=0),4)\n    accuracy = round(accuracy_score(y_test, y_predicted),4)\n    return accuracy, precision, recall, f1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treina um classificador, otimiza hiperparâmetros,\n# avalia performance e retorna métricas de desempenho\ndef build(X,y,vec,est,grid=None,n_splits=5,fit=True):\n    y_preds = []\n    scores_accuracy = []\n    scores_precision = []\n    scores_recall = []\n    scores_f1 = []\n    est_name = est.__class__.__name__\n    vec_name = vec.__class__.__name__\n    print(f'Testando o classificador {est_name} - {vec_name} ...')\n    # massa de dados\n    try:\n        X_data = vec.transform(X.tolist()).toarray()\n    except:\n        X_data = vec.transform(X.tolist())\n    y_data = y\n    # divida massa em folds\n    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n    if grid != None:\n        # faz o gridsearch\n        # uso F1 Macro como métrica\n        clf = GridSearchCV(est,grid,scoring='f1_macro',n_jobs=-1,cv=n_splits,verbose=100)\n        clf.fit(X_data,y_data)\n        estimator = clf.best_estimator_\n    else:\n        estimator = est\n        class DummyCLF: best_params_ = {}\n        clf = DummyCLF() \n    # faz validacao cruzada com kfold\n    for fold, (tr_idx, ts_idx) in enumerate(kf.split(X_data,y_data)):\n        # separa massas de treino/teste\n        X_tr, X_ts = X_data[tr_idx], X_data[ts_idx]\n        y_tr, y_ts = y_data[tr_idx], y_data[ts_idx]\n        if fit:\n            # treina\n            estimator.fit(X_tr, y_tr)\n        # avalia a performance\n        y_pr = estimator.predict(X_ts)\n        accuracy, precision, recall, f1 = get_metrics(y_ts, y_pr)\n        scores_accuracy.append(accuracy)\n        scores_precision.append(precision)\n        scores_recall.append(recall)\n        scores_f1.append(f1)\n\n    # obtém as métricas de desempenho - o quanto nosso classificador acertou?\n    accuracy = sum(scores_accuracy) / len(scores_accuracy);\n    precision = sum(scores_precision) / len(scores_precision);\n    recall = sum(scores_recall) / len(scores_recall);\n    f1 = sum(scores_f1) / len(scores_f1);\n\n    return estimator, est_name, vec_name, accuracy, precision, recall, f1, clf.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inicialização"},{"metadata":{},"cell_type":"markdown","source":"### Chatbots Disponívels para Treinamento\n\nA seguir a relação dos chatbots disponibilizados para o desafio.\n\nO \"*id*\"  é o identificador do chatbot. Ele está explícito aqui para evitar quaisquer dúvidas. O(s) classificador(es) deve(m) ser treinado(s) usando **ESTES** identificadores específicos. \n\nO identificador **0** (zero) deverá ser atribuído às perguntas que forem consideradas como **não** direcionadas a nenhum dos bots abaixo. Isso visa simular um ambiente real de orquestração, onde esse tipo de situação ocorre com frequência. Tais perguntas existirão apenas no arquivo de submissão, sem rótulos."},{"metadata":{"trusted":true},"cell_type":"code","source":"bots = [\n    {'id':0, 'nome':'Nenhum'},\n    {'id':1, 'nome':'Alistamento Militar'},\n    {'id':2, 'nome':'COVID'},\n    {'id':3, 'nome':'Login Único'},\n    {'id':4, 'nome':'IRPF - Perguntão 2020'},\n    {'id':5, 'nome':'PGMEI - Programa Gerador de DAS do Microempreendedor Individual'},\n    {'id':6, 'nome':'POC Selo Turismo Responsável'},\n    {'id':7, 'nome':'Cadastur - Cadastro dos Prestadores de Serviços Turísticos'},\n    {'id':8, 'nome':'Tuberculose'}\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Palavras-chave\n\nAs palavras-chave fortemente relacionadas aos assuntos (classes) são uma boa fonte de dados para uma classificação prévia."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Matriz de palavras-chave\n#\n# ordem: prioridade de avaliação\n# quaisquer palavras dentro de 'palavras' servem para classificar\n# palavras em MAIÚSCULO são avaliadas da forma como são (sem flexão)\n# palavras em minúsculo são flexionadas (exemplo: 'declarar' => 'declar')\n# expressões com mais de uma palavra, separadas por espaço, são avaliadas em conjunto (é necessário encontrar TODAS palavras-chave da expressão para classificar)\nkeywords = [\n    {'id': 0, 'palavras': [ # Assuntos não-relacionados: LGPD, INSS, Eleições, Trânsito/Detran\n        'LGPD',\n        'PROVA VIDA',\n        'TITULO eleitor','eleitor','votar','URNA','TRE','TSE',\n        'DETRAN','DENATRAN','CNH','CARTEIRA MOTORISTA','CARTEIRA HABILITACAO','primeira HABILITACAO','HABILITACAO PROVISORIA','CARTEIRA PROVISORIA',\n        'AUTO ESCOLA','RENAVAM','RENACH','AGENTE TRANSITO','aula pratica','dirigir','condutor'\n    ]},\n    {'id': 1, 'palavras': [ # Alistamento Militar\n        'alistamento','militar','EXERCITO','AERONAUTICA','MARINHA','FORCAS ARMADAS','FORCA servir','FORCA aerea','reservista','CTSM','juramento BANDEIRA',\n        'INCORPORACAO','CERTIFICADO DISPENSA','EXCESSO CONTINGENTE','SELECAO GERAL','CPOR','NPOR','CRDI','CERTIDAO REGISTRO DADOS INDIVIDUAIS',\n        'SELECAO dispensa','documento dispensa','TIRO GUERRA','TG'\n    ]},\n    {'id': 6, 'palavras': [ # Selo Turismo Responsável\n        'SELO turismo','SELO responsavel','SELO servico','SELO declarar','SELO higiene','SELO empreendimento','SELO atividade','SELO estabelecimento',\n        'SELO cadastro','SELO EMBRATUR','SELO CADASTUR','turismo RESPONSAVEL'\n    ]},\n    {'id': 7, 'palavras': [ # Cadastur\n        'CADASTUR','EMBRATUR','servico turismo','GUIA turismo'\n    ]},\n    {'id': 3, 'palavras': [ # Login Único\n        'LOGIN','LOGIN UNICO','CADASTRO UNICO','SENHA PROVISORIA'\n    ]},\n    {'id': 5, 'palavras': [ # PGMEI\n        'ICMS','IPI','ISS','GUIA DAS','gerar DAS','imprimir DAS'\n    ]},\n    {'id': 4, 'palavras': [ # IRPF 2020\n        'DIRPF','IRPF','RFB','SRF','GCAP','ECAC','CAC','DARF','MAED','IMPOSTO','RENDA','RERCT','PESSOA FISICA','RECEITA FEDERAL','DEPENDENTE','DEPENDENTES',\n        'restituir','declarar','isento','isencao','isencoes','deduzir','deducao','deducoes','dedutivel','abater',\n        'entregar DECLARACAO','entregar IRPF','entregar IMPOSTO','dispensa entregar',\n        'PRAZO estendido','PRAZO prorrogar','PRAZO adiar','PRAZO entregar','ATRASO entregar','PRAZO OUTRO PAIS','PRAZO FORA PAIS',\n        'CARNE LEAO','GANHO CAPITAL','valor BENS','valor BEM','relacionar BENS','SAIDA DEFINITIVA','PROGRAMA GERADOR IR','IMPOSTO FONTE','MALHA FINA','atividade RURAL',\n        'rendimentos recebidos ACUMULADAMENTE','NUMERO RECIBO','RECIBO ENTREGA','patrimonio','pagamento operadora','fonte pagadora',\n        'valor doacao','valor doacoes','limite doacao','limite doacoes','despesa instrucao','despesa educacao','despesa medica','despesa saude',\n        'desconto empregada','desconto diarista','rendimento','valor propriedade','retificar valor','retificar declaracao','valor recebido'\n    ]},\n    {'id': 5, 'palavras': [ # PGMEI\n        'PGMEI','MEI','microempreendedor','SISMEI','DASN','CNAE','NOME FANTASIA','EMPREENDEDOR INDIVIDUAL'\n    ]},\n    {'id': 2, 'palavras': [ # COVID-19\n        'COVID','CORONA','CORONAVIRUS','PANDEMIA','comorbidade',\n        'distancia contaminar','distancia contagio','distancia SOCIAL','ALCOOL GEL'\n    ]},\n    {'id': 8, 'palavras': [ # Tuberculose\n        'tuberculose','BACILO','KOCH','bacteria pulmonar'\n    ]},\n    {'id': 2, 'palavras': [ # COVID-19\n        'risco','china','MASCARA','lavar embalagem'\n    ]},\n    {'id': 0, 'palavras': [ # Assuntos não-relacionados: INSS, AIDS, Dengue, Lombriga, Hipertensão, Ansiedade\n        'INSS','aposentar','grupo TRANSICAO','regra TRANSICAO',\n        'HIV','AIDS','ATO SEXUAL','IMUNODEFICIENCIA',\n        'DENGUE','MOSQUITO',\n        'lombriga','verme',\n        'PRESSAO ALTA','hipertenso','PRESSAO ARTERIAL',\n        'ANSIEDADE'\n    ]},\n    {'id': 2, 'palavras': [ # COVID-19\n        'virus','contaminar','contagio','infectar'\n    ]},\n    {'id': 3, 'palavras': [ # Login Único\n        'SENHA','LOGAR','TERMO USO','GOV BR','PORTAL GOVERNO','PORTAL servico',\n        'DADOS apagar','DADOS remover','DADOS bloquear','DADOS desautorizar','DADOS desativar','DADOS utilizacao','DADOS PESSOAIS','autorizar DADOS'\n    ]},\n    {'id': 6, 'palavras': [ # Selo Turismo Responsável\n        'SELO','SELOS','hospedagem','resort','pousada','hotel','HOTEIS','albergue',\n        'turismo protocolo','viagem protocolo','empreendimento protocolo','servico protocolo','ANVISA protocolo','MTUR protocolo','DESTINO SEGURO',\n        'higiene','sanitarias',\n        'CGU','CONTROLADORIA GERAL UNIAO'\n    ]},\n    {'id': 1, 'palavras': [ # Alistamento Militar\n        'ARRIMO','SOLDO','dispensa'\n    ]},\n    {'id': 7, 'palavras': [ # Cadastur\n        'MARCA promocao','MARCA promover','MARCA divulgar','MARCA evento','USO MARCA','USAR MARCA'\n    ]},\n    \n    {'id':-1, 'palavras': []}, # Representa registro sem classificação\n]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Semente Aleatória\n\nSemente aleatória a ser usada ao longo desse notebook.\n\nProcure manter sempre a mesma semente aleatória (ou sementes aleatórias, caso utilize mais de uma). Deste modo, poderá comparar a evolução entre diferentes técnicas e também obter a reprodutibilidade exigida pelo regulamento do desafio.\n\nO valor da semente abaixo é apenas ilustrativo, fique à vontade para alterá-lo."},{"metadata":{"trusted":true},"cell_type":"code","source":"random_state=112020","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Elementos de NLP"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tokenizador: utilizado para separar uma frase em palavras.\ntokenizer = RegexpTokenizer(r'\\w+')\n\n# stopwords do português\nstopwords = nltk.corpus.stopwords.words('portuguese')\n\n# retira keywords da lista de stopwords\nfor item in keywords:\n    for phrase in item['palavras']:\n        for keyword in phrase.split():\n            kword = keyword.strip().lower()\n            if kword in stopwords:\n                stopwords.remove(kword)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Nomes dos Arquivos Utilizados\n\nNomes dos arquivos que serão utilizados ao longo deste notebook."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Caminho dos arquivos de entrada\ninput_path = '../input/desafio-ia-2020-pln-chatbots/'\n\n# Caminho dos arquivos de saída\noutput_path = '../working/'\n\n# Nome do arquivo CSV onde estão armazenadas as perguntas rotuladas, para treino e teste.\narquivo_treino_testes = input_path + 'treino_testes.csv'\n\n# Nome do arquivo CSV onde serão armazenadas as perguntas não rotuladas, para classificação e submissão.\n# Cada pergunta aqui conterá um identificador que deverá ser mantido.\narquivo_submissao = input_path + 'submissao.csv'\n\n# Nome do arquivo que será criado com os rótulos gerados pelo classificador.\n# Este é o arquivo que será submetido à página do desafio e que gerará um score.\n# Ele deverá conter apenas os identificadores das perguntas e os identificadores dos respectivos bots.\narquivo_submissao_classificado = output_path + 'submissao_equipe_{}.csv'\n\n# Nome do arquivo CSV de dados de submissão processados, para depuração\narquivo_dados_processados = output_path + 'processado_{}.csv'\n\n# Nome do arquivo CSV de dados classificados por keywords, para depuração\narquivo_dados_classificados = output_path + 'classificado_{}.csv'\n\n# Nome do arquivo CSV de dados não-classificados por keywords, para depuração\narquivo_dados_nao_classificados = output_path + 'nao_classificado_{}.csv'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apaga arquivos CSV de sessões anteriores no diretório de saída\nimport os\nfrom os import walk\n\nfor (dirpath, dirnames, filenames) in walk(output_path):\n    for filename in filenames:\n        if filename.endswith('.csv'):\n            os.remove(output_path + filename)\n            print(f'delete: {filename} ok.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Carregar os dados de treino e teste\n\nCarrega os dados do arquivo CSV com as perguntas rotuladas com os *ids* dos bots aos quais pertencem. Os rótulos variam de **1** a **8**, como pode ser conferido na lista de bots definida na seção **inicialização**. Estas perguntas serão usadas para treinamento e teste do(s) classificador(es).\n\nTodas as perguntas deste arquivo estão relacionadas a um (e apenas um) dos bots listados acima. Ou seja, não há nenhuma pergunta rotulada como **0** (zero). Este tipo de pergunta (não relacionada a nenhum dos bots) aparecerá **apenas no arquivo de submissão**."},{"metadata":{},"cell_type":"markdown","source":"### Dados de Treino e Teste"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Carrega o arquivo CSV\ndf = pd.read_csv(arquivo_treino_testes, index_col=None, engine='python', sep =',', encoding=\"utf-8\")\nprint('Total de registros carregados:',len(df))\n\n# Exibe uma amostra dos dados carregados\ndf.tail(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribuição das classes nos dados fornecidos. Note que não há nenhum pergunta rotulada como \"0\".\ndf.bot_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dados de Submissão"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Carrega o arquivo CSV\ndf_subm = pd.read_csv(arquivo_submissao, index_col=None, engine='python', sep =',', encoding=\"utf-8\")\nprint('Total de registros carregados:',len(df))\n\n# Exibe uma amostra dos dados carregados\ndf_subm.tail(-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparar os textos para classificação\n\nA preparação dos dados é uma das etapas mais importantes para se obter uma boa performance na classificação de textos, e pode significar a diferença entre o sucesso e o fracasso de um projeto."},{"metadata":{},"cell_type":"markdown","source":"### Dados de treino/teste"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Limpa os dados, preparando-os para classificação.\ndf['pergunta_original'] = df['pergunta']\ndf['pergunta'] = df['pergunta'].apply(limpar_texto)\ndf.tail(-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dados para submissão"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Limpa os dados, preparando-os para classificação.\ndf_subm['pergunta_original'] = df_subm['pergunta']\ndf_subm['pergunta'] = df_subm['pergunta'].apply(limpar_texto)\ndf_subm.tail(-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Obter um vetorizador\nNessa etapa, vamos obter um *vetorizador*. Seu objetivo é converter os textos em **vetores numéricos**, para então submetê-los aos algoritmos de classificação."},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidfVectorizer = TfidfVectorizer()\ntfidfVectorizer.fit_transform(df['pergunta'].tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Escolher um modelo preditivo, treinar e testar o modelo\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combinações de classificador/vetorizador\n# Vetorizador TfidfVectorizer\nestimators = [\n  {'est': LinearSVC(), \n   'grid':{\n       'random_state':[random_state],\n       'C':[1],\n   },\n   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n  {'est': SVC(), \n   'grid':{\n       'random_state':[random_state],\n       'C':[10],\n       'gamma':[1],\n       'kernel':['linear'],\n   },\n   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n  {'est': SGDClassifier(), \n   'grid':{\n       'random_state':[random_state],\n       'max_iter':[10000],\n       'loss': ['modified_huber'],\n       'class_weight':[None],\n       'tol':[1e-3],\n   },\n   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n#  {'est': ComplementNB(), \n#   'grid':{\n#       'norm':[True],\n#       'alpha':[1.3],\n#   },\n#   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n#  {'est': LogisticRegression(), \n#   'grid':{\n#       'random_state':[random_state],\n#       'max_iter':[10000],\n#   },\n#   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n#  {'est': XGBClassifier(), \n#   'grid':{ \n#      'random_state': [random_state],\n#      'nthread':[4],\n#      'objective':['reg:squarederror'],\n#      'learning_rate': [.03],\n#      'max_depth': [8],\n#      'min_child_weight': [4],\n#      'subsample': [.7],\n#      'colsample_bytree': [.7],\n#      'n_estimators': [80],\n#   },\n#   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n#  {'est': CatBoostClassifier(), \n#   'grid':{ \n#      'random_state':[random_state],\n#      'iterations':[100],\n#      'silent':[False],\n#      'learning_rate': [.03],\n#   },\n#   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n#  {'est': NearestCentroid(), \n#   'grid':{ \n#      'metric': ['euclidean'], \n#      'shrink_threshold': [None],\n#   },\n#   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n#  {'est': DecisionTreeClassifier(), \n#   'grid':{ \n#      'random_state':[random_state],\n#   },\n#   'vec': tfidfVectorizer, 'est_name':'', 'vec_name':'', 'precision':0.0, 'recall':0.0, 'accuracy':0.0, 'f1':0.0, 'params':{}},\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Treina/testa classificador/vetorizador\nn_splits = 5\nfor estimator in estimators:\n    estimator['est'], estimator['est_name'], estimator['vec_name'], estimator['accurracy'], estimator['precision'], estimator['recall'], estimator['f1'], estimator['params'] = build(df['pergunta'],df['bot_id'],estimator['vec'],estimator['est'],estimator['grid'],n_splits)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seleção do melhor classificador/vetorizador\ndef get_f1(estimator):\n    return estimator.get('f1')\n\nestimators.sort(key=get_f1, reverse=True)\n\nfor estimator in estimators:\n    e_name, v_name, f1, acc, prec, rc, e_params = estimator['est_name'], estimator['vec_name'], round(estimator['f1'],4), round(estimator['accurracy'],4), round(estimator['precision'],4), round(estimator['recall'],4), estimator['params']\n    print(f\"{e_name} - {v_name} - F1: {f1}, Acc: {acc}, Prec: {prec}, Rec: {rc} - Params: {e_params}\")\n\n# escolhe melhor classificador/vetorizador\nclf = estimators[0]['est']\nvectorizer = estimators[0]['vec']\nprint('\\nSelecionado: ',estimators[0]['est_name'],'-',estimators[0]['vec_name'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# escolhe manualmente classificador/vetorizador\n#index = 1\n#clf = estimators[index]['est']\n#vectorizer = estimators[index]['vec']\n#print('\\nSelecionado: ',estimators[index]['est_name'],'-',estimators[index]['vec_name'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classificar os registros não rotulados para o desafio\n\nDe forma cíclica, repita os passos acima testando outras preparações de dados, outros vetorizadores, outros parâmetros e outras técnicas de classificação. Quando estiver satisfeito com a performance do seu modelo, siga os passos abaixo.\n\nVamos agora treinar o classificador com **todos** os registros pré-rotulados. Este classificador será então utilizado para inferir os bots das perguntas não rotuladas do desafio, como veremos a seguir."},{"metadata":{},"cell_type":"markdown","source":"### Classificação por palavras-chave\n\nEste tipo de classificação visa melhorar a performance do estimador quando uma frase possui uma palavra-chave que define já classe automaticamente."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Treina o classificador KeywordClassifier\ndummyVectorizer = DummyVectorizer()\nkwClassifier = KeywordClassifier()\ndf_keywords = pd.DataFrame(keywords,columns=['id','palavras'])\n\nX_train = dummyVectorizer.transform(df_keywords['palavras'].tolist())\ny_train = df_keywords['id']\nkwClassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Testa performance do classificador/vetorizador\nn_splits = 5\ne, e_name, v_name, acc, prec, rc, f1, e_params = build(df['pergunta'],df['bot_id'],dummyVectorizer,kwClassifier,None,n_splits,False)\n\nprint(f\"{e_name} - {v_name} - F1: {round(f1,4)}, Acc: {round(acc,4)}, Prec: {round(prec,4)}, Rec: {round(rc,4)} - Params: {e_params}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Classifica registros se encontrar palavras-chave correspondentes\nX_test = dummyVectorizer.transform(df_subm['pergunta'].tolist())\ny_predicted = kwClassifier.predict(X_test)\ndf_subm['bot_id'] = y_predicted\n\n# Reordena registros\ndf_subm.sort_values('bot_id',inplace=True)\ndf_subm.reset_index(inplace=True,drop=True)\n\n# Nomeia registros para facilitar depuracao\ndf_subm['bot_nome'] = ''\nfor i in df_subm.index:\n    if df_subm['bot_id'][i] != -1:\n        df_subm['bot_nome'][i] = bots[df_subm['bot_id'][i]]['nome']\n# Exibe registros\ndf_subm.head(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# salva registros dos dados classificados, para análise\ndf_test = df_subm[df_subm['bot_id'] != -1]\ndf_test.to_csv(arquivo_dados_classificados.format((datetime.now() - timedelta(hours=3)).strftime('%Y-%m-%d_%H-%M-%S')), index=False, encoding=\"utf-8\", columns=['id','pergunta_original','bot_id','bot_nome'])\n\n# salva registros dos dados não-classificados, para análise\ndf_test = df_subm[df_subm['bot_id'] == -1]\ndf_test.to_csv(arquivo_dados_nao_classificados.format((datetime.now() - timedelta(hours=3)).strftime('%Y-%m-%d_%H-%M-%S')), index=False, encoding=\"utf-8\", columns=['id','pergunta_original','pergunta'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Treina o classificador com toda a base fornecida.\nX_train = vectorizer.transform(df['pergunta'].tolist()).toarray()\ny_train =  df['bot_id']\nclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vetoriza os textos que serão classificados.\n# Somente os que já não foram classificados anteriormente\ndf_test = df_subm[df_subm['bot_id'] == -1]\nX_test = vectorizer.transform(df_test['pergunta'].tolist()).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Executa a classificação dos registros não rotulados.\n# Somente os que já não foram classificados anteriormente\ny_predicted = clf.predict(X_test)\ndf_test['bot_id'] = y_predicted\nfor i in df_test.index:\n    df_subm['bot_id'][i] = df_test['bot_id'][i]\n\n# Nomeia registros para facilitar depuracao\ndf_subm['bot_nome'] = ''\nfor i in df_subm.index:\n    df_subm['bot_nome'][i] = bots[df_subm['bot_id'][i]]['nome']\n# Exibe registros\ndf_subm.head(-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gera matriz de probabilidades\n\nA matriz de probabilidades permite avaliar o quanto o estimador acertou a classificação de cada amostra, e assim, invalidar o resultado para classificações de baixa probabilidade (provavelmente deveriam ser da classe 0, 'Nenhum')"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gera matriz de probabilidades\ny_proba = []\ntry:\n    y_proba = clf.predict_proba(X_test)\nexcept:\n    try:\n        y_proba = clf.decision_function(X_test)\n    except:\n        pass\n\ndf_proba = pd.DataFrame()   \n\nif len(y_proba) > 0:\n    df_proba = pd.DataFrame(y_proba,columns=[1,2,3,4,5,6,7,8])\n    # normaliza para 0..1\n    pmin = df_proba.min().min()\n    pmax = df_proba.max().max()\n    df_proba = (df_proba - pmin) / (pmax - pmin)\n    probas = []\n    for i in df_proba.index:\n        # pega a distância entre min e max\n        n = [df_proba.iloc[i].min(), df_proba.iloc[i].max()]\n        proba = abs(n[1] - n[0])\n        probas.append(proba)\n    df_proba = pd.concat([df_proba,pd.DataFrame(probas,columns=['proba'])],axis=1)\n    \n# Exibe matriz\ndf_proba.head(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Corrige classificacao de baixa probabilidade\n# Provavelmente, esses registros pertencem a classe Nenhum (0)\n\n# considerei um valor de probabilidade mínimo aceitável\nproba_min = 0.2\ndf_subm['proba'] = df_proba['proba']\nbid_zero = bots[0]['id'] # classe zero\ncount = 0\nfor i in df_proba.index:\n    proba = df_proba['proba'][i]\n    if proba < proba_min: \n        df_subm['bot_id'][i] = bid_zero\n        count = count + 1\n\nprint(f'Desclassificados {count}/{len(df_subm.index)} registros com probabilidade abaixo de {proba_min*100.0}%.')\ndf_subm['proba'] = df_subm['proba'].fillna(1.0) # preenche NaN com 1.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Nomeia registros para facilitar depuracao\ndf_subm['bot_nome'] = ''\nfor i in df_subm.index:\n    df_subm['bot_nome'][i] = bots[df_subm['bot_id'][i]]['nome']\n# Exibe registros\ndf_subm.head(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# salva registros dos dados processados, para análise\ndf_subm.to_csv(arquivo_dados_processados.format((datetime.now() - timedelta(hours=3)).strftime('%Y-%m-%d_%H-%M-%S')), index=False, encoding=\"utf-8\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Salvar os registros classificados.\n\nApenas os identificadores das perguntas e os identificadores dos respectivos bots devem armazenados!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# salva registros classificados\ndf_subm.to_csv(arquivo_submissao_classificado.format((datetime.now() - timedelta(hours=3)).strftime('%Y-%m-%d_%H-%M-%S')), index=False, encoding=\"utf-8\", columns=['id','bot_id'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submeter os resultados à página do desafio\n\nEntre na página do desafio e faça o upload do arquivo *csv* obtido acima, com as classificações realizadas pelo seu modelo. Esse arquivo deve conter apenas as colunas \"*id*\" e \"*id_bot*\". O site irá calcular automaticamente sua métrica de acerto.\n\nSe o score obtido estiver nas três primeiras posições, faça um versionamento do código. Se esta posição se mantiver até o final da competição, ele será auditado para verificação de reprodutibilidade.\n\nVocê pode fazer quantas tentativas desejar, até atingir um limite diário (consulte o regulamento). Use isso para melhorar suas métricas."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}